{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d83424b3-0d0a-4f55-aa62-6e89de1add3e",
   "metadata": {},
   "source": [
    "# 表格内容生成文本实验"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe5823b-0af4-4c05-bc50-d861b541132f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T21:02:11.472142Z",
     "iopub.status.busy": "2024-09-04T21:02:11.471294Z",
     "iopub.status.idle": "2024-09-04T21:02:11.478212Z",
     "shell.execute_reply": "2024-09-04T21:02:11.476860Z",
     "shell.execute_reply.started": "2024-09-04T21:02:11.472080Z"
    }
   },
   "source": [
    "## 设定环境信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8e68583-2e6b-473d-9b9b-cad5eaaae033",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T21:12:54.483214Z",
     "iopub.status.busy": "2024-09-04T21:12:54.482384Z",
     "iopub.status.idle": "2024-09-04T21:12:54.494399Z",
     "shell.execute_reply": "2024-09-04T21:12:54.492850Z",
     "shell.execute_reply.started": "2024-09-04T21:12:54.483159Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU is CUDA:3\n",
      "CUDA:0 NVIDIA GeForce RTX 3090, 24252.6875MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM\n",
    ")\n",
    "\n",
    "os.environ[\"http_proxy\"] = \"http://10.6.0.17:8888\"\n",
    "os.environ[\"https_proxy\"] = \"http://10.6.0.17:8888\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "print(f\"Using GPU is CUDA:{os.environ['CUDA_VISIBLE_DEVICES']}\")\n",
    "\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    info = torch.cuda.get_device_properties(i)\n",
    "    print(f\"CUDA:{i} {info.name}, {info.total_memory / 1024 ** 2}MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc724f9c-7ad2-46a5-a80f-7ef512919b5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T21:59:06.398023Z",
     "iopub.status.busy": "2024-09-04T21:59:06.396152Z",
     "iopub.status.idle": "2024-09-04T21:59:06.408450Z",
     "shell.execute_reply": "2024-09-04T21:59:06.407386Z",
     "shell.execute_reply.started": "2024-09-04T21:59:06.397951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "组合以下内容：中国，海军，第一军区第二海军基地驱逐舰第三支队，052C型驱逐舰，1艘；052D驱逐舰，1艘；054A护卫舰，1艘，365，舰长 张胜利，政委 许强国，夏威夷附近海域，环太平洋-2024演习，上午12时00分00秒，持续进行，联合演习，西安舰；合肥舰；郴州舰\n"
     ]
    }
   ],
   "source": [
    "row = {\n",
    "    \"国别\": \"中国\",\n",
    "    \"军种\": \"海军\",\n",
    "    \"单位\": \"第一军区第二海军基地驱逐舰第三支队\",\n",
    "    \"装备\": \"052C型驱逐舰，1艘；052D驱逐舰，1艘；054A护卫舰，1艘\",\n",
    "    \"人数\": \"365\",\n",
    "    \"指挥员\": \"舰长 张胜利，政委 许强国\",\n",
    "    \"地点\": \"夏威夷附近海域\",\n",
    "    \"行动\": \"环太平洋-2024演习\",\n",
    "    \"开始时间\": \"上午12时00分00秒\",\n",
    "    \"任务状态\": \"持续进行\",\n",
    "    \"任务类型\": \"联合演习\",\n",
    "    \"备注\": \"西安舰；合肥舰；郴州舰\"\n",
    "}\n",
    "\n",
    "instruct = \"使用以下内容生成报告摘要：\" + \"，\".join(list(map(lambda k: row[k], row)))\n",
    "print(instruct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99af5b60-8f48-414b-abd4-bc069a4ea7da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T21:02:31.327273Z",
     "iopub.status.busy": "2024-09-04T21:02:31.326323Z",
     "iopub.status.idle": "2024-09-04T21:02:31.333130Z",
     "shell.execute_reply": "2024-09-04T21:02:31.332110Z",
     "shell.execute_reply.started": "2024-09-04T21:02:31.327207Z"
    }
   },
   "source": [
    "## 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe2102d-b9b0-4f85-a639-6052316b940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 使用 Baichuan2-7B-Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdee659a-3645-4db3-8189-7faa429b7c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"cache/models--baichuan-inc--Baichuan2-7B-Chat/snapshots/ea66ced17780ca3db39bc9f8aa601d8463db3da5\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_path, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    config=config,\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989d2eb7-19d0-456c-bd17-e92252b8517c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 使用 T5_pegasus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "729712cb-be23-4bf9-afad-808679af8d70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T22:03:58.277462Z",
     "iopub.status.busy": "2024-09-04T22:03:58.276536Z",
     "iopub.status.idle": "2024-09-04T22:08:00.282592Z",
     "shell.execute_reply": "2024-09-04T22:08:00.281802Z",
     "shell.execute_reply.started": "2024-09-04T22:03:58.277396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23270add40304805a0e544fbd040b67a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/437 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "768108ae797e4ccd8bdbfa61d475ff11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "952e67e8651c472eb18ac39f4b93d1dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/74.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b59cd579ced4a11b136c93322729040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/16.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef72bcdabcf4bde949b1d19987c01c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/766 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type mt5 to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc941250f7f49488143b32054b0dc31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本项目用海类型为“海域用海”,用海方式为“海\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"lambdarw/t5_pegasus_ch_ans\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"lambdarw/t5_pegasus_ch_ans\")\n",
    "\n",
    "input_ids = tokenizer(\"生成一篇关于冬天的文章\", return_tensors=\"pt\").input_ids\n",
    "outputs = model.generate(input_ids)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a4a603-0c83-488f-bdd4-79b4b0523b9e",
   "metadata": {},
   "source": [
    "## 测试文本生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23e75c08-4385-4f6b-b8af-b37f5d0e3b36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T22:08:30.276060Z",
     "iopub.status.busy": "2024-09-04T22:08:30.275179Z",
     "iopub.status.idle": "2024-09-04T22:08:31.198671Z",
     "shell.execute_reply": "2024-09-04T22:08:31.198142Z",
     "shell.execute_reply.started": "2024-09-04T22:08:30.275998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本项目用海类型为“海域用海”,用海方式为“海\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(instruct, return_tensors=\"pt\").input_ids\n",
    "outputs = model.generate(input_ids)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7495ed8a-0c90-4676-ae01-8f9826291b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(instruct, return_tensors='pt')\n",
    "inputs = inputs.to('cuda:0')\n",
    "pred = model.generate(**inputs, max_new_tokens=64, repetition_penalty=1.1)\n",
    "print(tokenizer.decode(pred.cpu()[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
