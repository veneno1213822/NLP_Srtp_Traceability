{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6fcf265-ce8d-4724-abe1-288bd76ccc8b",
   "metadata": {},
   "source": [
    "# vLLM适配笔记"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41712ccb-dc95-4832-b0d2-d014a9105cdd",
   "metadata": {},
   "source": [
    "## pytorch\n",
    "```\n",
    "pip install torch==2.4.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/test/cu121\n",
    "# 必须指定numpy版本，否则会出错\n",
    "pip install numpy==1.24.4\n",
    "```\n",
    "- 安装过程中，重新安装了`nvidia-cuda-runtime-cu12==12.1.105`，可能不需要使用cuda预制镜像，在安装torch过程中会自动安装cuda环境\n",
    "- 也有可能不需要`--index-url https://download.pytorch.org/whl/test/cu121`，只安装torch相关依赖，还需验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d83074c4-4ba4-49c6-8862-ed737189e1f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-24T14:13:29.357181Z",
     "iopub.status.busy": "2024-08-24T14:13:29.356782Z",
     "iopub.status.idle": "2024-08-24T14:13:30.678911Z",
     "shell.execute_reply": "2024-08-24T14:13:30.678019Z",
     "shell.execute_reply.started": "2024-08-24T14:13:29.357159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "4\n",
      "0\n",
      "NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "# 测试CUDA环境\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d2a17a-c5f1-4548-93dc-5d27c8694d89",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-08-23T16:13:07.891406Z",
     "iopub.status.busy": "2024-08-23T16:13:07.890481Z",
     "iopub.status.idle": "2024-08-23T16:13:07.897796Z",
     "shell.execute_reply": "2024-08-23T16:13:07.896396Z",
     "shell.execute_reply.started": "2024-08-23T16:13:07.891340Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## vllm 0.5.4\n",
    "```\n",
    "# 安装对应版本vllm\n",
    "wget https://github.com/vllm-project/vllm/releases/download/v0.5.4/vllm-0.5.4-cp310-cp310-manylinux1_x86_64.whl\n",
    "pip install vllm-0.5.4-cp310-cp310-manylinux1_x86_64.whl\n",
    "\n",
    "# 安装推理所需python库\n",
    "pip install bitsandbytes\n",
    "pip install peft==0.4.0\n",
    "\n",
    "# 安装 C/C++ 编译器\n",
    "apt-get install build-essential\n",
    "\n",
    "# 安装 dev版python\n",
    "apt install python3.10-dev\n",
    "```\n",
    "- 创建软连接\n",
    "```\n",
    "ln -s /opt/data/lora/ .\n",
    "ln -s /opt/data/cache/ .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11a1031-dee4-43c1-80be-a85aa75bd2b6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 测试加载已有模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c768fc6f-a2ef-43e4-9271-3590367fa60f",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-08-24T14:13:30.680354Z",
     "iopub.status.busy": "2024-08-24T14:13:30.679924Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n",
      "/usr/local/lib/python3.10/dist-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    GenerationConfig\n",
    ")\n",
    "from peft import PeftModel\n",
    "\n",
    "model_path = \"cache/models--baichuan-inc--Baichuan2-7B-Chat/snapshots/ea66ced17780ca3db39bc9f8aa601d8463db3da5\"\n",
    "lora_path = \"lora/baichuan7B-data2text-continue\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_path, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    config=config,\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(\n",
    "    model,\n",
    "    lora_path,\n",
    ")\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa914a63-c0bc-4ffa-b5da-2f509d07e004",
   "metadata": {},
   "source": [
    "### 测试简单推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bcc78d-cb97-4411-8b2f-70fad65bc33c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer('登鹳雀楼->王之涣\\n夜雨寄北->', return_tensors='pt')\n",
    "inputs = inputs.to('cuda:0')\n",
    "pred = model.generate(**inputs, max_new_tokens=64, repetition_penalty=1.1)\n",
    "print(tokenizer.decode(pred.cpu()[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e82c9ee-5618-461d-a92f-1466e9cdd377",
   "metadata": {},
   "source": [
    "### 测试LLM推理\n",
    "- 执行前建议**重启内核**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d558ea9f-43d4-4b10-ba56-409c2eab32e4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from vllm import LLM, SamplingParams\n",
    "from vllm.lora.request import LoRARequest\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    GenerationConfig\n",
    ")\n",
    "\n",
    "model_path = \"./cache/models--baichuan-inc--Baichuan2-7B-Chat/snapshots/ea66ced17780ca3db39bc9f8aa601d8463db3da5\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "config = AutoConfig.from_pretrained(model_path, trust_remote_code=True)\n",
    "\n",
    "llm = LLM(model_path, enable_lora=True, trust_remote_code=True)\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0,\n",
    "    max_tokens=256,\n",
    "    stop=[\"[/assistant]\"]\n",
    ")\n",
    "\n",
    "prompts = [\n",
    "     \"[user] 今天天气怎么样 [/user] [assistant]\",\n",
    "]\n",
    "\n",
    "outputs = llm.generate(\n",
    "    prompts,\n",
    "    sampling_params\n",
    ")\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743c774b-2ffb-4f51-8ac4-3d43ff108c2f",
   "metadata": {},
   "source": [
    "## 参考\n",
    "- [torch 2.4.0+cu121 quickstart](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html)\n",
    "- https://pytorch.org/get-started/locally/\n",
    "- [解决Python.h: No such file or directory](https://blog.csdn.net/dqchouyang/article/details/119571456)\n",
    "- [apt-get update 全部 ign怎么办](https://www.cnblogs.com/ldy233/p/13216860.html)\n",
    "- [Failed to find C compiler. Please specify via CC environment variable](https://github.com/vllm-project/vllm/issues/2997)\n",
    "- [numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject](https://stackoverflow.com/questions/78634235/numpy-dtype-size-changed-may-indicate-binary-incompatibility-expected-96-from)\n",
    "- [解决vllm部署时遇到的CUDA对应版本问题](https://juejin.cn/post/7386493960938176521)\n",
    "- https://github.com/vllm-project/vllm/releases\n",
    "- https://docs.vllm.ai/en/latest/dev/offline_inference/llm.html\n",
    "- https://docs.vllm.ai/en/latest/models/lora.html\n",
    "- [给vllm添加热添加lora的功能](https://www.cnblogs.com/alphainf/p/18227171)\n",
    "\n",
    "### Tips\n",
    "- CSDN和百度开发者中心的文章不要看，徒增抑郁+浪费生命"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
