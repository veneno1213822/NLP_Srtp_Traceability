{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "312082b8-41e9-4214-ba82-7d0feff8fc6a",
   "metadata": {},
   "source": [
    "# 指定训练使用显卡号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eab8fa1-cf2d-4f56-a67e-4b029db5abd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-10T04:30:03.599087Z",
     "iopub.status.busy": "2024-09-10T04:30:03.598705Z",
     "iopub.status.idle": "2024-09-10T04:30:03.609487Z",
     "shell.execute_reply": "2024-09-10T04:30:03.607935Z",
     "shell.execute_reply.started": "2024-09-10T04:30:03.599049Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8602ede4-446b-44b3-a0e7-c75d9af6b302",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-10T04:30:05.505107Z",
     "iopub.status.busy": "2024-09-10T04:30:05.504379Z",
     "iopub.status.idle": "2024-09-10T04:30:13.786245Z",
     "shell.execute_reply": "2024-09-10T04:30:13.785096Z",
     "shell.execute_reply.started": "2024-09-10T04:30:05.505066Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-10 04:30:08,395] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import oneke_trainer\n",
    "importlib.reload(oneke_trainer)\n",
    "from oneke_trainer import OneKETrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f5174f-ffe7-48a3-9ff3-03c1b315ad6f",
   "metadata": {},
   "source": [
    "# 训练参数\n",
    "包括基座模型，lora模型和训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74b6235f-12fe-4a07-96dc-9c69a76654e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-10T04:30:16.506956Z",
     "iopub.status.busy": "2024-09-10T04:30:16.506211Z",
     "iopub.status.idle": "2024-09-10T04:30:16.514421Z",
     "shell.execute_reply": "2024-09-10T04:30:16.512999Z",
     "shell.execute_reply.started": "2024-09-10T04:30:16.506894Z"
    }
   },
   "outputs": [],
   "source": [
    "model_path = \"cache/models--baichuan-inc--Baichuan2-7B-Chat/snapshots/ea66ced17780ca3db39bc9f8aa601d8463db3da5\"\n",
    "lora_path = \"lora/baichuan7B-data2text-continue\"\n",
    "data_path = \"data2text/data2text-test-all-v1-Copy1.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5780db77-0e85-490d-b6b5-28494494ac02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-10T04:30:19.508348Z",
     "iopub.status.busy": "2024-09-10T04:30:19.507499Z",
     "iopub.status.idle": "2024-09-10T04:30:19.515838Z",
     "shell.execute_reply": "2024-09-10T04:30:19.514450Z",
     "shell.execute_reply.started": "2024-09-10T04:30:19.508289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Training...\n"
     ]
    }
   ],
   "source": [
    "oneke_train = OneKETrainer(model_path, lora_path, data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42445692-0028-426a-a79e-69c8255500da",
   "metadata": {},
   "source": [
    "# 训练返回数据\n",
    "包括训练开始时间，训练结束时间，最大显存占用，使用显卡号，生成lora模型的路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcae5ffc-89b0-4b88-8ac6-eebb6b3a6064",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-10T04:31:02.455949Z",
     "iopub.status.busy": "2024-09-10T04:31:02.455100Z",
     "iopub.status.idle": "2024-09-10T04:36:47.077988Z",
     "shell.execute_reply": "2024-09-10T04:36:47.077114Z",
     "shell.execute_reply.started": "2024-09-10T04:31:02.455887Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "File renamed from /root/data2text-oneke/data2text/data2text_20240910/data2text-ner-train-val.jsonl to /root/data2text-oneke/data2text/data2text_20240910/data2text-ner-train-val-json.json\n",
      "File renamed from /root/data2text-oneke/data2text/data2text_20240910/data2text-ner-test.jsonl to /root/data2text-oneke/data2text/data2text_20240910/data2text-ner-test-json.json\n",
      "09/10/2024 04:31:02 - WARNING - args.parser - `ddp_find_unused_parameters` needs to be set as False for LoRA in DDP training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|training_args.py:1332] 2024-09-10 04:31:02,484 >> Found safetensors installation, but --save_safetensors=False. Safetensors should be a preferred weights saving format due to security and performance reasons. If your model cannot be saved by safetensors please feel free to open an issue at https://github.com/huggingface/safetensors!\n",
      "[INFO|training_args.py:1764] 2024-09-10 04:31:02,484 >> PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09/10/2024 04:31:02 - INFO - args.parser - Process rank: 0, device: cuda:0, n_gpu: 1\n",
      "  distributed training: True, compute dtype: torch.bfloat16\n",
      "09/10/2024 04:31:02 - INFO - args.parser - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=True,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=False,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=epoch,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_config=None,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=4,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=True,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/root/data2text-oneke/lora/NER_lora_model_20240910/runs/Sep10_04-31-02_06d8af42ca5a,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=2,\n",
      "logging_strategy=steps,\n",
      "loss_scale=1.0,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=0.5,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=10,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "output_dir=/root/data2text-oneke/lora/NER_lora_model_20240910,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=2,\n",
      "per_device_train_batch_size=2,\n",
      "predict_with_generate=False,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=False,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/root/data2text-oneke/lora/NER_lora_model_20240910,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=False,\n",
      "save_steps=500,\n",
      "save_strategy=epoch,\n",
      "save_total_limit=10,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "09/10/2024 04:31:02 - INFO - src.finetune - Start Time: 2024:09:10 04:31:02\n",
      "09/10/2024 04:31:02 - INFO - src.finetune - model_args:ModelArguments(model_name_or_path='cache/models--baichuan-inc--Baichuan2-7B-Chat/snapshots/ea66ced17780ca3db39bc9f8aa601d8463db3da5', model_name='baichuan', cache_dir=None, use_fast_tokenizer=True, trust_remote_code=True, use_auth_token=False, model_revision='main', split_special_tokens=False, bits=4, adam8bit=False, double_quant=True, quant_type='nf4', checkpoint_dir=['lora/baichuan7B-data2text-continue'])\n",
      "data_args:DataArguments(train_file='/root/data2text-oneke/data2text/data2text_20240910/data2text-ner-train-transformed.json', valid_file='/root/data2text-oneke/data2text/data2text_20240910/data2text-ner-val-transformed.json', predict_file=None, preprocessing_num_workers=16, overwrite_cache=False, cache_path=None, template='baichuan2', system_prompt=None, max_source_length=400, max_target_length=300, cutoff_len=700, val_set_size=1000, pad_to_max_length=False, ignore_pad_token_for_loss=True, train_on_prompt=False, language='zh', id_text='input')\n",
      "training_args:TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=True,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=False,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=epoch,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_config=None,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=4,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=True,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/root/data2text-oneke/lora/NER_lora_model_20240910/runs/Sep10_04-31-02_06d8af42ca5a,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=2,\n",
      "logging_strategy=steps,\n",
      "loss_scale=1.0,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=0.5,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=10,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "output_dir=/root/data2text-oneke/lora/NER_lora_model_20240910,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=2,\n",
      "per_device_train_batch_size=2,\n",
      "predict_with_generate=False,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=False,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/root/data2text-oneke/lora/NER_lora_model_20240910,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=False,\n",
      "save_steps=500,\n",
      "save_strategy=epoch,\n",
      "save_total_limit=10,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "finetuning_args:FinetuningArguments(dpo_beta=0.1, ppo_logger=None, ppo_score_norm=False, ppo_target=6.0, ppo_whiten_rewards=False, ref_model=None, ref_model_checkpoint=None, ref_model_quantization_bit=None, reward_model=None, reward_model_checkpoint=None, reward_model_quantization_bit=None, reward_model_type='lora', lora_r=64, lora_alpha=64, lora_dropout=0.05, lora_target_modules=['W_pack', 'o_proj', 'gate_proj', 'down_proj', 'up_proj'], additional_target=None, resume_lora_training=True, num_layer_trainable=3, name_module_trainable=['mlp'], stage='sft', finetuning_type='lora', upcast_layernorm=False, neft_alpha=0, export_dir=None, plot_loss=False)\n",
      "generating_args:GenerationArguments(max_length=512, max_new_tokens=256, min_new_tokens=None, do_sample=False, num_beams=1, num_beam_groups=1, penalty_alpha=None, use_cache=True, temperature=1.0, top_k=50, top_p=1.0, typical_p=1.0, diversity_penalty=0.0, repetition_penalty=1.0, length_penalty=1.0, no_repeat_ngram_size=0)\n",
      "09/10/2024 04:31:02 - INFO - src.finetune - model_class:<class 'transformers.models.auto.modeling_auto.AutoModelForCausalLM'>\n",
      "tokenizer_class:<class 'transformers.models.auto.tokenization_auto.AutoTokenizer'>\n",
      "trainer_class:<class 'transformers.trainer.Trainer'>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1677: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of 🤗 Transformers. Use `--hub_token` instead.\n",
      "  warnings.warn(\n",
      "[INFO|tokenization_utils_base.py:1850] 2024-09-10 04:31:02,497 >> loading file tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:1850] 2024-09-10 04:31:02,497 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:1850] 2024-09-10 04:31:02,498 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1850] 2024-09-10 04:31:02,498 >> loading file tokenizer_config.json\n",
      "[INFO|configuration_utils.py:713] 2024-09-10 04:31:02,554 >> loading configuration file cache/models--baichuan-inc--Baichuan2-7B-Chat/snapshots/ea66ced17780ca3db39bc9f8aa601d8463db3da5/config.json\n",
      "[INFO|configuration_utils.py:713] 2024-09-10 04:31:02,556 >> loading configuration file cache/models--baichuan-inc--Baichuan2-7B-Chat/snapshots/ea66ced17780ca3db39bc9f8aa601d8463db3da5/config.json\n",
      "[INFO|configuration_utils.py:775] 2024-09-10 04:31:02,557 >> Model config BaichuanConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"_name_or_path\": \"cache/models--baichuan-inc--Baichuan2-7B-Chat/snapshots/ea66ced17780ca3db39bc9f8aa601d8463db3da5\",\n",
      "  \"architectures\": [\n",
      "    \"BaichuanForCausalLM\"\n",
      "  ],\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_baichuan.BaichuanConfig\",\n",
      "    \"AutoModelForCausalLM\": \"modeling_baichuan.BaichuanForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"baichuan\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_class\": \"BaichuanTokenizer\",\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.33.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 125696,\n",
      "  \"z_loss_weight\": 0\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09/10/2024 04:31:02 - INFO - model.loader - Quantizing model to 4 bit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n",
      "[INFO|modeling_utils.py:2854] 2024-09-10 04:31:02,606 >> loading weights file cache/models--baichuan-inc--Baichuan2-7B-Chat/snapshots/ea66ced17780ca3db39bc9f8aa601d8463db3da5/pytorch_model.bin\n",
      "[INFO|modeling_utils.py:1200] 2024-09-10 04:31:12,901 >> Instantiating BaichuanForCausalLM model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:768] 2024-09-10 04:31:13,720 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.33.0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2971] 2024-09-10 04:31:13,963 >> Detected 4-bit loading: activating 4-bit loading for this model\n",
      "[INFO|modeling_utils.py:3643] 2024-09-10 04:31:28,894 >> All model checkpoint weights were used when initializing BaichuanForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:3651] 2024-09-10 04:31:28,896 >> All the weights of BaichuanForCausalLM were initialized from the model checkpoint at cache/models--baichuan-inc--Baichuan2-7B-Chat/snapshots/ea66ced17780ca3db39bc9f8aa601d8463db3da5.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BaichuanForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:728] 2024-09-10 04:31:28,900 >> loading configuration file cache/models--baichuan-inc--Baichuan2-7B-Chat/snapshots/ea66ced17780ca3db39bc9f8aa601d8463db3da5/generation_config.json\n",
      "[INFO|configuration_utils.py:768] 2024-09-10 04:31:28,901 >> Generate config GenerationConfig {\n",
      "  \"assistant_token_id\": 196,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"max_new_tokens\": 2048,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"repetition_penalty\": 1.05,\n",
      "  \"temperature\": 0.3,\n",
      "  \"top_k\": 5,\n",
      "  \"top_p\": 0.85,\n",
      "  \"transformers_version\": \"4.33.0\",\n",
      "  \"user_token_id\": 195\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09/10/2024 04:31:29 - INFO - model.adapter - Gradient checkpointing enabled.\n",
      "09/10/2024 04:31:29 - INFO - model.adapter - Fine-tuning method: LoRA\n",
      "09/10/2024 04:31:29 - INFO - model.adapter - Resume model checkpoint(s): lora/baichuan7B-data2text-continue .\n",
      "09/10/2024 04:32:14 - INFO - model.adapter - Loaded fine-tuned model from checkpoint(s): lora/baichuan7B-data2text-continue\n",
      "09/10/2024 04:32:14 - INFO - model.loader - trainable params: 143130624 || all params: 7649103872 || trainable%: 1.8712\n",
      "09/10/2024 04:32:14 - INFO - src.finetune - BOS:1,<s>\tEOS:2,</s>\tPAD:0,<unk>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-d5e107e102fab8e0\n",
      "Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n",
      "Generating dataset json (/root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96...\n",
      "Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "Generating train split\n",
      "Generating train split: 100 examples [00:00, 1278.12 examples/s]\n",
      "Unable to verify splits sizes.\n",
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96. Subsequent calls will reuse this data.\n",
      "Using custom data configuration default-35eb21852551bf7e\n",
      "Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n",
      "Generating dataset json (/root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96...\n",
      "Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "Generating train split\n",
      "Generating train split: 25 examples [00:00, 10683.40 examples/s]\n",
      "Unable to verify splits sizes.\n",
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96. Subsequent calls will reuse this data.\n",
      "[INFO|tokenization_utils_base.py:926] 2024-09-10 04:32:15,872 >> Assigning [] to the additional_special_tokens key of the tokenizer\n",
      "Process #0 will write at /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0d14562c31db9a11_00000_of_00016.arrow\n",
      "Process #1 will write at /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0d14562c31db9a11_00001_of_00016.arrow\n",
      "Process #2 will write at /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0d14562c31db9a11_00002_of_00016.arrow\n",
      "Process #3 will write at /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0d14562c31db9a11_00003_of_00016.arrow\n",
      "Process #4 will write at /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0d14562c31db9a11_00004_of_00016.arrow\n",
      "Process #5 will write at /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0d14562c31db9a11_00005_of_00016.arrow\n",
      "Process #6 will write at /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0d14562c31db9a11_00006_of_00016.arrow\n",
      "Process #7 will write at /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0d14562c31db9a11_00007_of_00016.arrow\n",
      "Process #8 will write at /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0d14562c31db9a11_00008_of_00016.arrow\n",
      "Process #9 will write at /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0d14562c31db9a11_00009_of_00016.arrow\n",
      "Process #10 will write at /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0d14562c31db9a11_00010_of_00016.arrow\n",
      "Process #11 will write at /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0d14562c31db9a11_00011_of_00016.arrow\n",
      "Process #12 will write at /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0d14562c31db9a11_00012_of_00016.arrow\n",
      "Process #13 will write at /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0d14562c31db9a11_00013_of_00016.arrow\n",
      "Process #14 will write at /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0d14562c31db9a11_00014_of_00016.arrow\n",
      "Process #15 will write at /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0d14562c31db9a11_00015_of_00016.arrow\n",
      "Spawning 16 processes\n",
      "Map (num_proc=16):   0%|          | 0/100 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0d14562c31db9a11_00004_of_00016.arrow\n",
      "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0d14562c31db9a11_00005_of_00016.arrow\n",
      "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0d14562c31db9a11_00006_of_00016.arrow\n",
      "Map (num_proc=16):   6%|▌         | 6/100 [00:00<00:02, 32.20 examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0d14562c31db9a11_00011_of_00016.arrow\n",
      "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0d14562c31db9a11_00012_of_00016.arrow\n",
      "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0d14562c31db9a11_00009_of_00016.arrow\n",
      "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0d14562c31db9a11_00000_of_00016.arrow\n",
      "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0d14562c31db9a11_00013_of_00016.arrow\n",
      "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0d14562c31db9a11_00015_of_00016.arrow\n",
      "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0d14562c31db9a11_00014_of_00016.arrow\n",
      "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0d14562c31db9a11_00002_of_00016.arrow\n",
      "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0d14562c31db9a11_00001_of_00016.arrow\n",
      "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0d14562c31db9a11_00003_of_00016.arrow\n",
      "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0d14562c31db9a11_00010_of_00016.arrow\n",
      "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0d14562c31db9a11_00007_of_00016.arrow\n",
      "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-d5e107e102fab8e0/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-0d14562c31db9a11_00008_of_00016.arrow\n",
      "Map (num_proc=16): 100%|██████████| 100/100 [00:00<00:00, 269.93 examples/s]\n",
      "Concatenating 16 shards\n",
      "[INFO|tokenization_utils_base.py:926] 2024-09-10 04:32:16,787 >> Assigning [] to the additional_special_tokens key of the tokenizer\n",
      "Process #0 will write at /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ad2b8cc2e8f76ab5_00000_of_00016.arrow\n",
      "Process #1 will write at /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ad2b8cc2e8f76ab5_00001_of_00016.arrow\n",
      "Process #2 will write at /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ad2b8cc2e8f76ab5_00002_of_00016.arrow\n",
      "Process #3 will write at /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ad2b8cc2e8f76ab5_00003_of_00016.arrow\n",
      "Process #4 will write at /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ad2b8cc2e8f76ab5_00004_of_00016.arrow\n",
      "Process #5 will write at /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ad2b8cc2e8f76ab5_00005_of_00016.arrow\n",
      "Process #6 will write at /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ad2b8cc2e8f76ab5_00006_of_00016.arrow\n",
      "Process #7 will write at /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ad2b8cc2e8f76ab5_00007_of_00016.arrow\n",
      "Process #8 will write at /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ad2b8cc2e8f76ab5_00008_of_00016.arrow\n",
      "Process #9 will write at /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ad2b8cc2e8f76ab5_00009_of_00016.arrow\n",
      "Process #10 will write at /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ad2b8cc2e8f76ab5_00010_of_00016.arrow\n",
      "Process #11 will write at /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ad2b8cc2e8f76ab5_00011_of_00016.arrow\n",
      "Process #12 will write at /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ad2b8cc2e8f76ab5_00012_of_00016.arrow\n",
      "Process #13 will write at /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ad2b8cc2e8f76ab5_00013_of_00016.arrow\n",
      "Process #14 will write at /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ad2b8cc2e8f76ab5_00014_of_00016.arrow\n",
      "Process #15 will write at /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ad2b8cc2e8f76ab5_00015_of_00016.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids:\n",
      "[195, 30338, 9571, 4256, 5338, 1664, 8225, 7048, 1697, 12242, 29090, 86566, 66, 92676, 92569, 12269, 92364, 93689, 24352, 3550, 46272, 12316, 92333, 12242, 65, 92349, 13601, 12242, 6315, 10078, 92842, 27303, 66, 92676, 2592, 38498, 59124, 94200, 92333, 14499, 7293, 66, 2925, 1664, 46272, 5338, 50154, 7837, 2925, 1664, 7837, 6919, 2925, 1664, 7837, 4956, 2925, 1664, 7837, 6315, 65226, 1664, 12269, 5338, 1664, 5317, 2365, 4104, 7323, 3591, 2756, 8401, 9808, 93331, 23550, 12725, 6699, 92649, 41113, 9808, 15117, 66, 16032, 92538, 2841, 2072, 2019, 2274, 92595, 1850, 92505, 1925, 11219, 30385, 11705, 1805, 66, 52639, 196, 30338, 7837, 5338, 86381, 1664, 7837, 6919, 5338, 86381, 1664, 7837, 4956, 5338, 86381, 1664, 7837, 6315, 5338, 27381, 92795, 2]\n",
      "inputs:\n",
      " <reserved_106>{\"instruction\": \"你是专门进行实体抽取的专家。请从input中抽取出符合schema定义的实体，不存在的实体类型返回空列表。请按照JSON字符串的格式回答。\", \"schema\": [\"装备\", \"装备名称\", \"装备数量\", \"装备类型\"], \"input\": \"一份关于成立航空设备集团公司的总统令草案已被提交给普京总统签署。该公司将包括所有技术系统科学生产中心的企业以及其他一系列企业。\"}<reserved_107>{\"装备\": [], \"装备名称\": [], \"装备数量\": [], \"装备类型\": []}</s>\n",
      "label_ids:\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 30338, 7837, 5338, 86381, 1664, 7837, 6919, 5338, 86381, 1664, 7837, 4956, 5338, 86381, 1664, 7837, 6315, 5338, 27381, 92795, 2]\n",
      "labels:\n",
      " {\"装备\": [], \"装备名称\": [], \"装备数量\": [], \"装备类型\": []}</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Spawning 16 processes\n",
      "Map (num_proc=16):   0%|          | 0/25 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ad2b8cc2e8f76ab5_00000_of_00016.arrow\n",
      "Map (num_proc=16):   8%|▊         | 2/25 [00:00<00:01, 11.56 examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ad2b8cc2e8f76ab5_00015_of_00016.arrow\n",
      "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ad2b8cc2e8f76ab5_00009_of_00016.arrow\n",
      "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ad2b8cc2e8f76ab5_00010_of_00016.arrow\n",
      "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ad2b8cc2e8f76ab5_00014_of_00016.arrow\n",
      "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ad2b8cc2e8f76ab5_00012_of_00016.arrow\n",
      "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ad2b8cc2e8f76ab5_00011_of_00016.arrow\n",
      "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ad2b8cc2e8f76ab5_00006_of_00016.arrow\n",
      "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ad2b8cc2e8f76ab5_00003_of_00016.arrow\n",
      "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ad2b8cc2e8f76ab5_00002_of_00016.arrow\n",
      "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ad2b8cc2e8f76ab5_00004_of_00016.arrow\n",
      "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ad2b8cc2e8f76ab5_00005_of_00016.arrow\n",
      "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ad2b8cc2e8f76ab5_00001_of_00016.arrow\n",
      "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ad2b8cc2e8f76ab5_00013_of_00016.arrow\n",
      "Map (num_proc=16):  20%|██        | 5/25 [00:00<00:01, 14.53 examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ad2b8cc2e8f76ab5_00008_of_00016.arrow\n",
      "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-35eb21852551bf7e/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-ad2b8cc2e8f76ab5_00007_of_00016.arrow\n",
      "Map (num_proc=16): 100%|██████████| 25/25 [00:00<00:00, 48.34 examples/s]\n",
      "Concatenating 16 shards\n",
      "[INFO|trainer.py:403] 2024-09-10 04:32:17,875 >> The model is quantized. To train this model you need to add additional modules inside the model such as adapters using `peft` library and freeze the model weights. Please check the examples in https://github.com/huggingface/peft for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids:\n",
      "[195, 30338, 9571, 4256, 5338, 1664, 8225, 7048, 1697, 12242, 29090, 86566, 66, 92676, 92569, 12269, 92364, 93689, 24352, 3550, 46272, 12316, 92333, 12242, 65, 92349, 13601, 12242, 6315, 10078, 92842, 27303, 66, 92676, 2592, 38498, 59124, 94200, 92333, 14499, 7293, 66, 2925, 1664, 46272, 5338, 50154, 3461, 3531, 2925, 1664, 3461, 6315, 2925, 1664, 92892, 92534, 2925, 1664, 2020, 65226, 1664, 12269, 5338, 1664, 61358, 37594, 9821, 62579, 57664, 18988, 92364, 16561, 3546, 10485, 6004, 65, 92594, 2904, 92489, 7830, 92405, 25780, 62579, 92385, 52774, 93604, 92666, 1697, 6624, 66, 52639, 196, 30338, 3461, 3531, 5338, 86381, 1664, 3461, 6315, 5338, 86381, 1664, 92892, 92534, 5338, 86381, 1664, 2020, 5338, 27381, 92795, 2]\n",
      "inputs:\n",
      " <reserved_106>{\"instruction\": \"你是专门进行实体抽取的专家。请从input中抽取出符合schema定义的实体，不存在的实体类型返回空列表。请按照JSON字符串的格式回答。\", \"schema\": [\"任务状态\", \"任务类型\", \"军种\", \"单位\"], \"input\": \"奥巴马想在未来的核武器削减谈判中引入新的武器分类，并准备与俄罗斯就战术核武器和贮存弹头进行讨论。\"}<reserved_107>{\"任务状态\": [], \"任务类型\": [], \"军种\": [], \"单位\": []}</s>\n",
      "label_ids:\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 30338, 3461, 3531, 5338, 86381, 1664, 3461, 6315, 5338, 86381, 1664, 92892, 92534, 5338, 86381, 1664, 2020, 5338, 27381, 92795, 2]\n",
      "labels:\n",
      " {\"任务状态\": [], \"任务类型\": [], \"军种\": [], \"单位\": []}</s>\n",
      "09/10/2024 04:32:17 - INFO - src.finetune - *** Train ***\n",
      "09/10/2024 04:32:17 - INFO - src.finetune - resume_from_checkpoint: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:1712] 2024-09-10 04:32:18,124 >> ***** Running training *****\n",
      "[INFO|trainer.py:1713] 2024-09-10 04:32:18,125 >>   Num examples = 100\n",
      "[INFO|trainer.py:1714] 2024-09-10 04:32:18,126 >>   Num Epochs = 10\n",
      "[INFO|trainer.py:1715] 2024-09-10 04:32:18,127 >>   Instantaneous batch size per device = 2\n",
      "[INFO|trainer.py:1718] 2024-09-10 04:32:18,127 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "[INFO|trainer.py:1719] 2024-09-10 04:32:18,128 >>   Gradient Accumulation steps = 4\n",
      "[INFO|trainer.py:1720] 2024-09-10 04:32:18,129 >>   Total optimization steps = 120\n",
      "[INFO|trainer.py:1721] 2024-09-10 04:32:18,133 >>   Number of trainable parameters = 143,130,624\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/120 04:23, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.011504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.005964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.005489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.009272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.010081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.009388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.009254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.008988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.009032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.009112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3115] 2024-09-10 04:32:42,111 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3117] 2024-09-10 04:32:42,113 >>   Num examples = 25\n",
      "[INFO|trainer.py:3120] 2024-09-10 04:32:42,114 >>   Batch size = 2\n",
      "[INFO|trainer.py:2841] 2024-09-10 04:32:44,090 >> Saving model checkpoint to /root/data2text-oneke/lora/NER_lora_model_20240910/checkpoint-12\n",
      "[INFO|trainer.py:3115] 2024-09-10 04:33:09,517 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3117] 2024-09-10 04:33:09,518 >>   Num examples = 25\n",
      "[INFO|trainer.py:3120] 2024-09-10 04:33:09,519 >>   Batch size = 2\n",
      "[INFO|trainer.py:2841] 2024-09-10 04:33:11,517 >> Saving model checkpoint to /root/data2text-oneke/lora/NER_lora_model_20240910/checkpoint-25\n",
      "[INFO|trainer.py:3115] 2024-09-10 04:33:37,017 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3117] 2024-09-10 04:33:37,019 >>   Num examples = 25\n",
      "[INFO|trainer.py:3120] 2024-09-10 04:33:37,020 >>   Batch size = 2\n",
      "[INFO|trainer.py:2841] 2024-09-10 04:33:39,014 >> Saving model checkpoint to /root/data2text-oneke/lora/NER_lora_model_20240910/checkpoint-37\n",
      "[INFO|trainer.py:3115] 2024-09-10 04:34:04,703 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3117] 2024-09-10 04:34:04,705 >>   Num examples = 25\n",
      "[INFO|trainer.py:3120] 2024-09-10 04:34:04,705 >>   Batch size = 2\n",
      "[INFO|trainer.py:2841] 2024-09-10 04:34:06,696 >> Saving model checkpoint to /root/data2text-oneke/lora/NER_lora_model_20240910/checkpoint-50\n",
      "[INFO|trainer.py:3115] 2024-09-10 04:34:32,258 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3117] 2024-09-10 04:34:32,259 >>   Num examples = 25\n",
      "[INFO|trainer.py:3120] 2024-09-10 04:34:32,260 >>   Batch size = 2\n",
      "[INFO|trainer.py:2841] 2024-09-10 04:34:34,251 >> Saving model checkpoint to /root/data2text-oneke/lora/NER_lora_model_20240910/checkpoint-62\n",
      "[INFO|trainer.py:3115] 2024-09-10 04:34:59,899 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3117] 2024-09-10 04:34:59,900 >>   Num examples = 25\n",
      "[INFO|trainer.py:3120] 2024-09-10 04:34:59,901 >>   Batch size = 2\n",
      "[INFO|trainer.py:2841] 2024-09-10 04:35:01,890 >> Saving model checkpoint to /root/data2text-oneke/lora/NER_lora_model_20240910/checkpoint-75\n",
      "[INFO|trainer.py:3115] 2024-09-10 04:35:27,488 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3117] 2024-09-10 04:35:27,489 >>   Num examples = 25\n",
      "[INFO|trainer.py:3120] 2024-09-10 04:35:27,490 >>   Batch size = 2\n",
      "[INFO|trainer.py:2841] 2024-09-10 04:35:29,483 >> Saving model checkpoint to /root/data2text-oneke/lora/NER_lora_model_20240910/checkpoint-87\n",
      "[INFO|trainer.py:3115] 2024-09-10 04:35:55,026 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3117] 2024-09-10 04:35:55,027 >>   Num examples = 25\n",
      "[INFO|trainer.py:3120] 2024-09-10 04:35:55,028 >>   Batch size = 2\n",
      "[INFO|trainer.py:2841] 2024-09-10 04:35:57,018 >> Saving model checkpoint to /root/data2text-oneke/lora/NER_lora_model_20240910/checkpoint-100\n",
      "[INFO|trainer.py:3115] 2024-09-10 04:36:22,474 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3117] 2024-09-10 04:36:22,475 >>   Num examples = 25\n",
      "[INFO|trainer.py:3120] 2024-09-10 04:36:22,476 >>   Batch size = 2\n",
      "[INFO|trainer.py:2841] 2024-09-10 04:36:24,468 >> Saving model checkpoint to /root/data2text-oneke/lora/NER_lora_model_20240910/checkpoint-112\n",
      "[INFO|trainer.py:3115] 2024-09-10 04:36:40,640 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3117] 2024-09-10 04:36:40,641 >>   Num examples = 25\n",
      "[INFO|trainer.py:3120] 2024-09-10 04:36:40,642 >>   Batch size = 2\n",
      "[INFO|trainer.py:2841] 2024-09-10 04:36:42,631 >> Saving model checkpoint to /root/data2text-oneke/lora/NER_lora_model_20240910/checkpoint-120\n",
      "[INFO|trainer.py:1960] 2024-09-10 04:36:44,436 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:2841] 2024-09-10 04:36:44,440 >> Saving model checkpoint to /root/data2text-oneke/lora/NER_lora_model_20240910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =        9.6\n",
      "  total_flos               =  3116356GF\n",
      "  train_loss               =     0.0076\n",
      "  train_runtime            = 0:04:26.30\n",
      "  train_samples_per_second =      3.755\n",
      "  train_steps_per_second   =      0.451\n",
      "09/10/2024 04:36:45 - INFO - src.finetune - *** Evaluate ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3115] 2024-09-10 04:36:45,073 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3117] 2024-09-10 04:36:45,074 >>   Num examples = 25\n",
      "[INFO|trainer.py:3120] 2024-09-10 04:36:45,075 >>   Batch size = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =        9.6\n",
      "  eval_loss               =     0.0091\n",
      "  eval_runtime            = 0:00:01.99\n",
      "  eval_samples_per_second =     12.517\n",
      "  eval_steps_per_second   =      6.509\n",
      "09/10/2024 04:36:47 - INFO - src.finetune - End Time: 2024:09:10 04:36:47\n"
     ]
    }
   ],
   "source": [
    "start_time, end_time, max_memory_allocated, gpu_index, lora_output_path = oneke_train.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9d29cd4-5343-465c-9c86-4057862a7503",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T03:44:25.450197Z",
     "iopub.status.busy": "2024-09-05T03:44:25.449339Z",
     "iopub.status.idle": "2024-09-05T03:44:25.457407Z",
     "shell.execute_reply": "2024-09-05T03:44:25.456479Z",
     "shell.execute_reply.started": "2024-09-05T03:44:25.450136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-05,03:38:19 2024-09-05,03:44:09 7218160640 1 /root/data2text-oneke/lora/NER_lora_model_20240905\n"
     ]
    }
   ],
   "source": [
    "print(start_time, end_time, max_memory_allocated, gpu_index, lora_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94830427-93bc-4390-972b-8b6ca3ec95a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
