{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2005ce39-2906-424e-a624-e59ff2bb6f1d",
   "metadata": {},
   "source": [
    "1.\n",
    "把max_new_tokens调小，300过长"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc30e99-6c5c-4dff-826f-79746b7f1511",
   "metadata": {},
   "source": [
    "2.\n",
    "vllm加速推理\n",
    "推荐环境:\n",
    "\n",
    "```bash\n",
    "pip install tiktoken\n",
    "pip install peft==0.7.1\n",
    "pip install transformers==4.41.2\n",
    "\n",
    "pip install vllm==0.3.0\n",
    "pip install jinja2==3.0.1\n",
    "pip install pydantic==1.9.2\n",
    "\n",
    "ip route add 8.8.8.8 via 127.0.0.1\n",
    "```\n",
    "\n",
    "\n",
    "```bash\n",
    "python src/infer_vllm.py \\\n",
    "    --stage sft \\\n",
    "    --model_name_or_path 'lora_results/baichuan2-13b-v1/baichuan2-13b-v1' \\\n",
    "    --model_name 'baichuan' \\\n",
    "    --template 'baichuan2' \\\n",
    "    --do_predict \\\n",
    "    --input_file 'data/input.json' \\\n",
    "    --output_file 'results/baichuan2-13b-IEPile-lora_output.json' \\\n",
    "    --output_dir 'lora_results/test' \\\n",
    "    --batch_size 4 \\\n",
    "    --predict_with_generate \\\n",
    "    --max_source_length 1024 \\\n",
    "    --bf16 \\\n",
    "    --max_new_tokens 512\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45d7232-08ac-4313-b778-966d73683a37",
   "metadata": {},
   "source": [
    "3. \n",
    "现在问答的schema定义包含十个，对于不同的样例，可能会造成浪费。实际一条文本包含的schema可能很少，schema过多会导致推理较慢。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
