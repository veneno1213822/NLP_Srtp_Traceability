{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9667c087-92a7-4e1a-836e-b166c6875308",
   "metadata": {},
   "source": [
    "# Baichuan2-7B IEPile 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2afcb957-9362-47d8-a99e-5d24d14cb6dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T11:08:23.669971Z",
     "iopub.status.busy": "2024-08-30T11:08:23.669281Z",
     "iopub.status.idle": "2024-08-30T11:08:23.678728Z",
     "shell.execute_reply": "2024-08-30T11:08:23.678072Z",
     "shell.execute_reply.started": "2024-08-30T11:08:23.669921Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"http_proxy\"] = \"http://10.6.0.17:8888\"\n",
    "os.environ[\"https_proxy\"] = \"http://10.6.0.17:8888\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1280acc3-4796-4d2f-9764-f9affa635a88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T09:10:51.504816Z",
     "iopub.status.busy": "2024-08-29T09:10:51.503996Z",
     "iopub.status.idle": "2024-08-29T09:10:51.510988Z",
     "shell.execute_reply": "2024-08-29T09:10:51.509674Z",
     "shell.execute_reply.started": "2024-08-29T09:10:51.504754Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caa99722-5224-4840-b102-0da68bf4875e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T11:08:26.660719Z",
     "iopub.status.busy": "2024-08-30T11:08:26.659952Z",
     "iopub.status.idle": "2024-08-30T11:08:32.734387Z",
     "shell.execute_reply": "2024-08-30T11:08:32.733411Z",
     "shell.execute_reply.started": "2024-08-30T11:08:26.660671Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-30 11:08:28,874] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    GenerationConfig\n",
    ")\n",
    "from peft import PeftModel\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_path = 'cache/models--baichuan-inc--Baichuan2-7B-Chat/snapshots/ea66ced17780ca3db39bc9f8aa601d8463db3da5'\n",
    "lora_path = 'lora/baichuan7B-data2text-continue'\n",
    "config = AutoConfig.from_pretrained(model_path, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a9e052b-7e12-47c0-afa7-9685ee5eaa71",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-08-12T06:31:26.145849Z",
     "iopub.status.busy": "2024-08-12T06:31:26.144825Z",
     "iopub.status.idle": "2024-08-12T06:31:32.721033Z",
     "shell.execute_reply": "2024-08-12T06:31:32.719997Z",
     "shell.execute_reply.started": "2024-08-12T06:31:26.145758Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Loading baichuan-inc/Baichuan2-7B-Chat requires to execute some code in that repo, you can inspect the content of the repository at https://hf.co/baichuan-inc/Baichuan2-7B-Chat. You can dismiss this prompt by passing `trust_remote_code=True`.\n",
      "Do you accept? [y/N]  y\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unrecognized configuration class <class 'transformers_modules.baichuan-inc.Baichuan2-7B-Chat.ea66ced17780ca3db39bc9f8aa601d8463db3da5.configuration_baichuan.BaichuanConfig'> for this kind of AutoModel: AutoModel.\nModel type should be one of AlbertConfig, AlignConfig, AltCLIPConfig, ASTConfig, AutoformerConfig, BarkConfig, BartConfig, BeitConfig, BertConfig, BertGenerationConfig, BigBirdConfig, BigBirdPegasusConfig, BioGptConfig, BitConfig, BlenderbotConfig, BlenderbotSmallConfig, BlipConfig, Blip2Config, BloomConfig, BridgeTowerConfig, CamembertConfig, CanineConfig, ChineseCLIPConfig, ClapConfig, CLIPConfig, CLIPSegConfig, LlamaConfig, CodeGenConfig, ConditionalDetrConfig, ConvBertConfig, ConvNextConfig, ConvNextV2Config, CpmAntConfig, CTRLConfig, CvtConfig, Data2VecAudioConfig, Data2VecTextConfig, Data2VecVisionConfig, DebertaConfig, DebertaV2Config, DecisionTransformerConfig, DeformableDetrConfig, DeiTConfig, DetaConfig, DetrConfig, DinatConfig, Dinov2Config, DistilBertConfig, DonutSwinConfig, DPRConfig, DPTConfig, EfficientFormerConfig, EfficientNetConfig, ElectraConfig, EncodecConfig, ErnieConfig, ErnieMConfig, EsmConfig, FalconConfig, FlaubertConfig, FlavaConfig, FNetConfig, FocalNetConfig, FSMTConfig, FunnelConfig, GitConfig, GLPNConfig, GPT2Config, GPT2Config, GPTBigCodeConfig, GPTNeoConfig, GPTNeoXConfig, GPTNeoXJapaneseConfig, GPTJConfig, GPTSanJapaneseConfig, GraphormerConfig, GroupViTConfig, HubertConfig, IBertConfig, IdeficsConfig, ImageGPTConfig, InformerConfig, JukeboxConfig, LayoutLMConfig, LayoutLMv2Config, LayoutLMv3Config, LEDConfig, LevitConfig, LiltConfig, LlamaConfig, LongformerConfig, LongT5Config, LukeConfig, LxmertConfig, M2M100Config, MarianConfig, MarkupLMConfig, Mask2FormerConfig, MaskFormerConfig, MaskFormerSwinConfig, MBartConfig, MCTCTConfig, MegaConfig, MegatronBertConfig, MgpstrConfig, MobileBertConfig, MobileNetV1Config, MobileNetV2Config, MobileViTConfig, MobileViTV2Config, MPNetConfig, MptConfig, MraConfig, MT5Config, MvpConfig, NatConfig, NezhaConfig, NllbMoeConfig, NystromformerConfig, OneFormerConfig, OpenLlamaConfig, OpenAIGPTConfig, OPTConfig, OwlViTConfig, PegasusConfig, PegasusXConfig, PerceiverConfig, PLBartConfig, PoolFormerConfig, ProphetNetConfig, PvtConfig, QDQBertConfig, ReformerConfig, RegNetConfig, RemBertConfig, ResNetConfig, RetriBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig, RoFormerConfig, RwkvConfig, SamConfig, SegformerConfig, SEWConfig, SEWDConfig, Speech2TextConfig, SpeechT5Config, SplinterConfig, SqueezeBertConfig, SwiftFormerConfig, SwinConfig, Swin2SRConfig, Swinv2Config, SwitchTransformersConfig, T5Config, TableTransformerConfig, TapasConfig, TimeSeriesTransformerConfig, TimesformerConfig, TimmBackboneConfig, TrajectoryTransformerConfig, TransfoXLConfig, TvltConfig, UMT5Config, UniSpeechConfig, UniSpeechSatConfig, VanConfig, VideoMAEConfig, ViltConfig, VisionTextDualEncoderConfig, VisualBertConfig, ViTConfig, ViTHybridConfig, ViTMAEConfig, ViTMSNConfig, VitDetConfig, VitsConfig, VivitConfig, Wav2Vec2Config, Wav2Vec2ConformerConfig, WavLMConfig, WhisperConfig, XCLIPConfig, XGLMConfig, XLMConfig, XLMProphetNetConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, XmodConfig, YolosConfig, YosoConfig.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m save_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./models\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 下载并加载模型\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# config = AutoConfig.from_pretrained(model_name, trust_remote_code=True)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/auto/auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    564\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    565\u001b[0m     )\n\u001b[0;32m--> 566\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized configuration class <class 'transformers_modules.baichuan-inc.Baichuan2-7B-Chat.ea66ced17780ca3db39bc9f8aa601d8463db3da5.configuration_baichuan.BaichuanConfig'> for this kind of AutoModel: AutoModel.\nModel type should be one of AlbertConfig, AlignConfig, AltCLIPConfig, ASTConfig, AutoformerConfig, BarkConfig, BartConfig, BeitConfig, BertConfig, BertGenerationConfig, BigBirdConfig, BigBirdPegasusConfig, BioGptConfig, BitConfig, BlenderbotConfig, BlenderbotSmallConfig, BlipConfig, Blip2Config, BloomConfig, BridgeTowerConfig, CamembertConfig, CanineConfig, ChineseCLIPConfig, ClapConfig, CLIPConfig, CLIPSegConfig, LlamaConfig, CodeGenConfig, ConditionalDetrConfig, ConvBertConfig, ConvNextConfig, ConvNextV2Config, CpmAntConfig, CTRLConfig, CvtConfig, Data2VecAudioConfig, Data2VecTextConfig, Data2VecVisionConfig, DebertaConfig, DebertaV2Config, DecisionTransformerConfig, DeformableDetrConfig, DeiTConfig, DetaConfig, DetrConfig, DinatConfig, Dinov2Config, DistilBertConfig, DonutSwinConfig, DPRConfig, DPTConfig, EfficientFormerConfig, EfficientNetConfig, ElectraConfig, EncodecConfig, ErnieConfig, ErnieMConfig, EsmConfig, FalconConfig, FlaubertConfig, FlavaConfig, FNetConfig, FocalNetConfig, FSMTConfig, FunnelConfig, GitConfig, GLPNConfig, GPT2Config, GPT2Config, GPTBigCodeConfig, GPTNeoConfig, GPTNeoXConfig, GPTNeoXJapaneseConfig, GPTJConfig, GPTSanJapaneseConfig, GraphormerConfig, GroupViTConfig, HubertConfig, IBertConfig, IdeficsConfig, ImageGPTConfig, InformerConfig, JukeboxConfig, LayoutLMConfig, LayoutLMv2Config, LayoutLMv3Config, LEDConfig, LevitConfig, LiltConfig, LlamaConfig, LongformerConfig, LongT5Config, LukeConfig, LxmertConfig, M2M100Config, MarianConfig, MarkupLMConfig, Mask2FormerConfig, MaskFormerConfig, MaskFormerSwinConfig, MBartConfig, MCTCTConfig, MegaConfig, MegatronBertConfig, MgpstrConfig, MobileBertConfig, MobileNetV1Config, MobileNetV2Config, MobileViTConfig, MobileViTV2Config, MPNetConfig, MptConfig, MraConfig, MT5Config, MvpConfig, NatConfig, NezhaConfig, NllbMoeConfig, NystromformerConfig, OneFormerConfig, OpenLlamaConfig, OpenAIGPTConfig, OPTConfig, OwlViTConfig, PegasusConfig, PegasusXConfig, PerceiverConfig, PLBartConfig, PoolFormerConfig, ProphetNetConfig, PvtConfig, QDQBertConfig, ReformerConfig, RegNetConfig, RemBertConfig, ResNetConfig, RetriBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig, RoFormerConfig, RwkvConfig, SamConfig, SegformerConfig, SEWConfig, SEWDConfig, Speech2TextConfig, SpeechT5Config, SplinterConfig, SqueezeBertConfig, SwiftFormerConfig, SwinConfig, Swin2SRConfig, Swinv2Config, SwitchTransformersConfig, T5Config, TableTransformerConfig, TapasConfig, TimeSeriesTransformerConfig, TimesformerConfig, TimmBackboneConfig, TrajectoryTransformerConfig, TransfoXLConfig, TvltConfig, UMT5Config, UniSpeechConfig, UniSpeechSatConfig, VanConfig, VideoMAEConfig, ViltConfig, VisionTextDualEncoderConfig, VisualBertConfig, ViTConfig, ViTHybridConfig, ViTMAEConfig, ViTMSNConfig, VitDetConfig, VitsConfig, VivitConfig, Wav2Vec2Config, Wav2Vec2ConformerConfig, WavLMConfig, WhisperConfig, XCLIPConfig, XGLMConfig, XLMConfig, XLMProphetNetConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, XmodConfig, YolosConfig, YosoConfig."
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# 模型名称或路径\n",
    "model_name = \"baichuan-inc/Baichuan2-7B-Chat\"\n",
    "\n",
    "# 保存路径\n",
    "save_directory = \"./models\"\n",
    "\n",
    "# 下载并加载模型\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "# config = AutoConfig.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "# 保存模型和tokenizer到指定路径\n",
    "model.save_pretrained(save_directory)\n",
    "tokenizer.save_pretrained(save_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fa3c1fb-36a4-4c18-a93d-7c701427e7fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T11:08:53.794522Z",
     "iopub.status.busy": "2024-08-30T11:08:53.794204Z",
     "iopub.status.idle": "2024-08-30T11:11:16.937034Z",
     "shell.execute_reply": "2024-08-30T11:11:16.936437Z",
     "shell.execute_reply.started": "2024-08-30T11:08:53.794500Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): BaichuanForCausalLM(\n",
       "      (model): BaichuanModel(\n",
       "        (embed_tokens): Embedding(125696, 4096, padding_idx=0)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x DecoderLayer(\n",
       "            (self_attn): Attention(\n",
       "              (W_pack): Linear(\n",
       "                in_features=4096, out_features=12288, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=12288, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): Linear(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (rotary_emb): RotaryEmbedding()\n",
       "            )\n",
       "            (mlp): MLP(\n",
       "              (gate_proj): Linear(\n",
       "                in_features=4096, out_features=11008, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=11008, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (down_proj): Linear(\n",
       "                in_features=11008, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=11008, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (up_proj): Linear(\n",
       "                in_features=4096, out_features=11008, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=11008, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "            (input_layernorm): RMSNorm()\n",
       "            (post_attention_layernorm): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (lm_head): NormHead()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    config=config,\n",
    "    device_map=\"auto\",  \n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "model = PeftModel.from_pretrained(\n",
    "    model,\n",
    "    lora_path,\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75dd2df0-d4fb-4ac8-84ba-bb02f240b720",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T08:51:48.362131Z",
     "iopub.status.busy": "2024-08-11T08:51:48.361301Z",
     "iopub.status.idle": "2024-08-11T08:51:48.449524Z",
     "shell.execute_reply": "2024-08-11T08:51:48.448423Z",
     "shell.execute_reply.started": "2024-08-11T08:51:48.362068Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3d2a7cb-17e1-4cf6-8e3c-3f19e2620241",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T11:12:04.868675Z",
     "iopub.status.busy": "2024-08-30T11:12:04.868118Z",
     "iopub.status.idle": "2024-08-30T11:12:21.603971Z",
     "shell.execute_reply": "2024-08-30T11:12:21.603145Z",
     "shell.execute_reply.started": "2024-08-30T11:12:04.868648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"时间\": [\"明年\", \"2014年\", \"2013年\"], \"人物\": [\"梅尔华拉海军上将\"], \"国家\": [\"印度\"], \"装备名称\": [\"第1艘完全自主生产的航母\", \"第2艘国产航母\", \"维拉特号\"], \"装备类型\": [\"航母\", \"防空舰\"], \"装备数量\": [\"1艘\", \"1艘\", \"1艘\"], \"组织机构\": [\"印度海军\"]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "system_prompt = '<<SYS>>\\n 你是一个乐于助人的助手。\\n<</SYS>>\\n\\n'\n",
    "\n",
    "# sintruct = json.dumps(\n",
    "#     {\n",
    "#         \"instruction\": \"你是一个图谱实体知识结构化专家。根据输入实体类型(entity type)的schema描述，从文本中抽取出相应的实体实例和其属性信息，不存在的属性不输出, 属性存在多值就返回列表，并输出为可解析的json格式。\", \n",
    "#         \"schema\": [\n",
    "#             {\n",
    "#                 \"entity_type\": \"人物\", \n",
    "#                 \"attributes\": \n",
    "#                 {\n",
    "#                     \"中文名\": \"人物中文名字\", \n",
    "#                     \"英文名\": \"人物的英文名\", \n",
    "#                     \"祖籍\": \"人物的祖籍地址\", \n",
    "#                     \"出生日期\": \"生日、出生年月日\", \n",
    "#                     \"出生地点\": \"出生的地点、行政区\", \n",
    "#                     \"职业\": \"人物的职业、职务、身份\", \n",
    "#                     \"毕业学校\": \"就读毕业的中学、大学、高校\", \n",
    "#                     \"作品\": \"专辑、歌曲、小说、出版书籍、参演影视作品等\", \n",
    "#                     \"奖项\": \"人物所获得的各种奖项和荣誉称号\"\n",
    "#                 }\n",
    "#             }\n",
    "#         ], \n",
    "#         \"input\": \"周杰伦（Jay Chou），1979年1月18日出生于台湾省新北市，祖籍福建省泉州市永春县，华语流行乐男歌手、音乐人、演员、导演、编剧，毕业于淡江中学。2000年，发行个人首张音乐专辑《Jay》。2001年，凭借专辑《范特西》奠定其融合中西方音乐的风格。2002年，举行“The One”世界巡回演唱会；同年，凭借歌曲《爱在西元前》获得第13届台湾金曲奖最佳作曲人奖。\"}\n",
    "#     , ensure_ascii=False\n",
    "# )\n",
    "\n",
    "# 第48030行数据\n",
    "sintruct = json.dumps(\n",
    "    {\n",
    "        \"instruction\": \"你是一个命名实体识别专家。请从input中抽取符合schema描述的实体，如果实体类型不存在就返回空列表，并输出为可解析的json格式。\", \n",
    "        \"schema\": [\"时间\", \"人物\", \"国家\", \"装备名称\", \"装备类型\", \"装备数量\", \"组织机构\", \"地点\"], \n",
    "        \"input\": \"印度海军的梅尔华拉海军上将透露，明年印度将会下水第1艘完全自主生产的航母，并计划在2014年实现服役，同时第2艘国产航母的建造也将得到批准。此外，排水量为40000吨的印度国产防空舰正在科钦船厂建造，而维拉特号则将于2013年退役。\"\n",
    "    }, \n",
    "    ensure_ascii=False\n",
    ")\n",
    "\n",
    "# sintruct = json.dumps(\n",
    "#     {\n",
    "#         \"instruction\": \"你是一个命名实体识别专家。请从input中抽取符合schema描述的实体，如果实体类型不存在就返回空列表，并输出为可解析的json格式。\", \n",
    "#         \"schema\": [\"时间\",\"人物\",\"国家\",\"装备名称\",\"装备类型\",\"装备数量\",\"组织机构\",\"地点\",\"任务\",\"行动\",\"事件\",\"备注\"], \n",
    "#         \"input\": \"7,11月20日,德国KMW公司,德国,豹2主战坦克,主战坦克,1000.0,德国KMW公司,未提及,纪念这款传奇主战坦克诞生40周年,举办了一场别开生面的生日会,豹2系列坦克诞生40周年,40年来，豹2系列坦克一直是西方三代坦克的标杆，并深刻的影响了日本90式坦克、印度阿琼坦克、土耳其阿尔泰坦克等其他国家三代主战坦克的发展,8,5月16日,姜克红,俄罗斯,米-35M武装直升机,武装直升机,1,第6届俄罗斯国际直升机工业展,莫斯科,展出,参展,第6届俄罗斯国际直升机工业展开幕,当日，第6届俄罗斯国际直升机工业展在莫斯科开幕，共吸引来自18个国家的205家厂商参展，其中包括欧洲直升机公司、阿古斯塔和俄罗斯直升机公司等世界直升机制造巨头,9,三九寒天,塔台指挥员,未明确,直升机,未明确,10.0,第78集团军某陆航旅,东北某机场,开展大规模机群远距离转场飞行,腾空而起,提高部队在各种复杂多变气象条件下攻防能力,三九寒天东北某机场马达轰鸣，随着塔台指挥员一声令下，第78集团军某陆航旅数十架直升机依次腾空而起飞往千里之外的高原某机场，开展大规模机群远距离转场飞行，提高部队在各种复杂多变气象条件下攻防能力,\"\n",
    "#     }, \n",
    "#     ensure_ascii=False\n",
    "# )\n",
    "\n",
    "sintruct = '<reserved_106>' + sintruct + '<reserved_107>'\n",
    "# sintruct = '<reserved_106>' + system_prompt + sintruct + '<reserved_107>'\n",
    "# sintruct = '[INST] ' + system_prompt + sintruct + ' [/INST]'\n",
    "\n",
    "input_ids = tokenizer.encode(sintruct, return_tensors=\"pt\").to(device)\n",
    "input_length = input_ids.size(1)\n",
    "\n",
    "generation_output = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    generation_config=GenerationConfig(\n",
    "        max_length=1024,\n",
    "        max_new_tokens=256,\n",
    "        return_dict_in_generate=True),\n",
    "    pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "generation_output = generation_output.sequences[0]\n",
    "generation_output = generation_output[input_length:]\n",
    "output = tokenizer.decode(generation_output, skip_special_tokens=True)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee381bdd-c97c-406d-96d5-c0fe7a8061e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T09:58:18.696299Z",
     "iopub.status.busy": "2024-08-11T09:58:18.695387Z",
     "iopub.status.idle": "2024-08-11T09:58:18.701839Z",
     "shell.execute_reply": "2024-08-11T09:58:18.701203Z",
     "shell.execute_reply.started": "2024-08-11T09:58:18.696215Z"
    }
   },
   "outputs": [],
   "source": [
    "# 转换为JSON对象\n",
    "result = json.loads(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1cccb9a-4924-4ab3-948b-676e8ea948e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T09:47:44.227739Z",
     "iopub.status.busy": "2024-08-11T09:47:44.227289Z",
     "iopub.status.idle": "2024-08-11T09:47:44.233763Z",
     "shell.execute_reply": "2024-08-11T09:47:44.233036Z",
     "shell.execute_reply.started": "2024-08-11T09:47:44.227709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON 文件已生成\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# output 是已经有的\n",
    "\n",
    "# 将 output 放入字典的 result 字段\n",
    "data = {\n",
    "    \"result\": output\n",
    "}\n",
    "\n",
    "# 将字典保存为一个 JSON 文件\n",
    "with open(\"results/test-useless2.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"JSON 文件已生成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "039e8ce5-5f5e-4d99-9ec4-50435e8a9037",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T09:48:08.278532Z",
     "iopub.status.busy": "2024-08-11T09:48:08.278110Z",
     "iopub.status.idle": "2024-08-11T09:48:08.315639Z",
     "shell.execute_reply": "2024-08-11T09:48:08.315127Z",
     "shell.execute_reply.started": "2024-08-11T09:48:08.278505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "匹配的字典位置: 第一层数组的第 15 个元素中的第二层数组的第 0 个字典\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def find_matching_dict(file_path, content):\n",
    "    # 读取JSON文件\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # 遍历第一层数组\n",
    "    for i, sublist in enumerate(data):\n",
    "        # 遍历第二层数组\n",
    "        for j, dictionary in enumerate(sublist):\n",
    "            # 检查text字段是否包含指定的内容\n",
    "            if 'text' in dictionary and content in dictionary['text']:\n",
    "                return (i, j)\n",
    "\n",
    "    return None\n",
    "\n",
    "# 示例用法\n",
    "file_path = 'data2text/data2text-test-all-v1.json'\n",
    "content = '美国海军的诺格公司E-2D先进鹰眼预警机即将开始进行初始作战试验和评估阶段，并计划在2014年第四季度与空基早期告警和控制系统一起实现初始作战能力。目前，已有四架E-2D被移交至美国海军航空测试和评估1中队，初始作战试验和评估将在2012年第二季度进行。'\n",
    "position = find_matching_dict(file_path, content)\n",
    "\n",
    "if position:\n",
    "    print(f\"匹配的字典位置: 第一层数组的第 {position[0]} 个元素中的第二层数组的第 {position[1]} 个字典\")\n",
    "else:\n",
    "    print(\"没有找到匹配的字典\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "283f2dc8-7c7d-4641-9ae1-636f1bf7a85e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T10:38:24.304418Z",
     "iopub.status.busy": "2024-08-11T10:38:24.303659Z",
     "iopub.status.idle": "2024-08-11T10:38:24.349573Z",
     "shell.execute_reply": "2024-08-11T10:38:24.348745Z",
     "shell.execute_reply.started": "2024-08-11T10:38:24.304363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'table': {'header': ['时间', '人物', '国家', '装备名称', '装备类型', '装备数量', '组织机构', '地点', '任务', '行动', '事件'], 'data': {'2': ['2014年第四季度', '美国海军', '美国', 'E-2D先进鹰眼预警机', '预警机', '四架', '诺格公司', '美国海军航空测试和评估1中队', '初始作战试验和评估', '开始进行初始作战试验和评估阶段', '与空基早期告警和控制系统一起实现初始作战能力'], '3': ['2012年第二季度', '', '', '', '', '', '', '', '', '', '']}}, 'origin': {}, 'text': '美国海军的诺格公司E-2D先进鹰眼预警机即将开始进行初始作战试验和评估阶段，并计划在2014年第四季度与空基早期告警和控制系统一起实现初始作战能力。目前，已有四架E-2D被移交至美国海军航空测试和评估1中队，初始作战试验和评估将在2012年第二季度进行。'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def save_second_layer(file_path, output_path, first_layer_index):\n",
    "    # 读取JSON文件\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # 检查索引是否在范围内\n",
    "    if first_layer_index >= len(data):\n",
    "        # print(f\"第一层数组的索引 {first_layer_index} 超出范围\")\n",
    "        return\n",
    "\n",
    "    # 获取第二层数组\n",
    "    second_layer = data[first_layer_index]\n",
    "    \n",
    "\n",
    "    # 将第二层数组保存为新的JSON文件\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(second_layer, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    # print(f\"成功保存第二层数组到 {output_path}\")\n",
    "    return second_layer\n",
    "\n",
    "# 示例用法\n",
    "file_path = 'data2text/data2text-test-all-v1.json'  # 原始JSON文件路径\n",
    "output_path = 'results/test-useless2-input.json'  # 新的JSON文件路径\n",
    "first_layer_index = position[0]  # 第一层数组的索引\n",
    "second_layer_index = position[1]  # 第一层数组的索引\n",
    "\n",
    "print(save_second_layer(file_path, output_path, first_layer_index))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f16f808-b1a1-4ba2-abda-68819895a52c",
   "metadata": {},
   "source": [
    "## 生成verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9fdc0c38-b7b7-4e95-81f7-cf6d719cd86f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:08:07.380511Z",
     "iopub.status.busy": "2024-08-11T12:08:07.380101Z",
     "iopub.status.idle": "2024-08-11T12:08:07.390405Z",
     "shell.execute_reply": "2024-08-11T12:08:07.389155Z",
     "shell.execute_reply.started": "2024-08-11T12:08:07.380490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'table': {'header': ['时间', '人物', '国家', '装备名称', '装备类型', '装备数量', '组织机构', '地点', '任务', '行动', '事件'], 'data': {'2': ['2014年第四季度', '美国海军', '美国', 'E-2D先进鹰眼预警机', '预警机', '四架', '诺格公司', '美国海军航空测试和评估1中队', '初始作战试验和评估', '开始进行初始作战试验和评估阶段', '与空基早期告警和控制系统一起实现初始作战能力'], '3': ['2012年第二季度', '', '', '', '', '', '', '', '', '', '']}}, 'origin': {}, 'text': '美国海军的诺格公司E-2D先进鹰眼预警机即将开始进行初始作战试验和评估阶段，并计划在2014年第四季度与空基早期告警和控制系统一起实现初始作战能力。目前，已有四架E-2D被移交至美国海军航空测试和评估1中队，初始作战试验和评估将在2012年第二季度进行。'}] \n",
      "\n",
      "{'时间': ['2014年第四季度', '2012年第二季度'], '人物': [], '国家': [], '装备名称': ['E-2D先进鹰眼预警机'], '装备类型': ['预警机'], '装备数量': ['四架'], '组织机构': ['诺格公司'], '地点': ['美国海军航空测试和评估1中队'], '任务': [], '行动': [], '事件': []}\n"
     ]
    }
   ],
   "source": [
    "file_path = 'results/test-useless2-input.json'\n",
    "result_path = 'results/test-useless2.json'\n",
    "pth1 = 'results/input.json'\n",
    "pth2 = 'results/result.json'\n",
    "\n",
    "# with open(pth1, 'r', encoding='utf-8') as f:\n",
    "#         input_data = json.load(f)\n",
    "\n",
    "# with open(pth2, 'r', encoding='utf-8') as f:\n",
    "#         result_data = json.load(f)\n",
    "\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        input_data = json.load(f)\n",
    "\n",
    "with open(result_path, 'r', encoding='utf-8') as f:\n",
    "        result_data = json.load(f)\n",
    "\n",
    "# with open(file_path, 'w', encoding='utf-8') as f:\n",
    "#         json.dump(input_data, f, ensure_ascii=False, indent=4)\n",
    "# with open(result_path, 'w', encoding='utf-8') as f:\n",
    "#         json.dump(result_dict, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(input_data, '\\n')\n",
    "print(result_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bcd6adab-6a74-45c0-98ca-80315cf98d7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T10:28:16.336262Z",
     "iopub.status.busy": "2024-08-11T10:28:16.335718Z",
     "iopub.status.idle": "2024-08-11T10:28:16.342024Z",
     "shell.execute_reply": "2024-08-11T10:28:16.341112Z",
     "shell.execute_reply.started": "2024-08-11T10:28:16.336228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(input_data))\n",
    "print(type(result_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5c3014a8-43c6-43f0-80c6-d8c79e2732bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T10:24:31.659670Z",
     "iopub.status.busy": "2024-08-11T10:24:31.658881Z",
     "iopub.status.idle": "2024-08-11T10:24:31.666695Z",
     "shell.execute_reply": "2024-08-11T10:24:31.665466Z",
     "shell.execute_reply.started": "2024-08-11T10:24:31.659616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2': ['2014年第四季度', '美国海军', '美国', 'E-2D先进鹰眼预警机', '预警机', '四架', '诺格公司', '美国海军航空测试和评估1中队', '初始作战试验和评估', '开始进行初始作战试验和评估阶段', '与空基早期告警和控制系统一起实现初始作战能力'], '3': ['2012年第二季度', '', '', '', '', '', '', '', '', '', '']}\n"
     ]
    }
   ],
   "source": [
    "print(input_data[0]['table']['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a755fdee-3988-4c28-a1bd-e851332cb4ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T10:11:05.386585Z",
     "iopub.status.busy": "2024-08-11T10:11:05.385808Z",
     "iopub.status.idle": "2024-08-11T10:11:05.392584Z",
     "shell.execute_reply": "2024-08-11T10:11:05.391527Z",
     "shell.execute_reply.started": "2024-08-11T10:11:05.386514Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'table': {'header': ['时间', '人物', '国家', '装备名称', '装备类型', '装备数量', '组织机构', '地点', '任务', '行动', '事件'], 'data': {'2': ['9月初', '欧空局与俄罗斯联邦航天局', '欧空局成员国', '航天器', '乘员运输系统', '未明确', '欧空局与俄罗斯联邦航天局', '未明确', '载人月球飞行、初步系统设计、详细子系统设计以及合作机制和协议的制定', '启动乘员运输系统计划', '计划通过了资金和法律文件的审批'], '3': ['', '约7个国家', '', '对接装置', '未明确', '未明确', '未明确', '未明确', '确定已选航天器的全尺寸研发分工', '提供资金', '资金提供总计1870万美元'], '4': ['', 'NASA', '', '对接装置', '未明确', '未明确', 'NASA', '未明确', '参与设计', '参与设计对接装置', '可能包括NASA参与设计的对接装置']}}, 'origin': {}, 'text': '欧空局与俄罗斯联邦航天局计划于9月初启动乘员运输系统计划，已经通过了欧空局成员国的资金和法律文件的审批。据悉，约7个国家将为该计划提供总计1870万美元的资金，该计划将历时18个月，主要包括四个工作领域：载人月球飞行、初步系统设计、详细子系统设计以及合作机制和协议的制定。同时，该计划还将确定已选航天器的全尺寸研发分工，可能包括NASA参与设计的对接装置。', 'verify': {'2': [None, '欧空局与俄罗斯联邦航天局', None, None, None, None, '欧空局与俄罗斯联邦航天局', None, '载人月球飞行、初步系统设计、详细子系统设计以及合作机制和协议的制定', '启动乘员运输系统计划', None], '3': [None, None, None, None, None, None, None, None, '确定已选航天器的全尺寸研发分工', None, None], '4': [None, None, None, None, None, None, None, None, '参与设计', '参与设计对接装置', '可能包括NASA参与设计的对接装置']}}]\n"
     ]
    }
   ],
   "source": [
    "print(indict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6794dd73-27ba-4f40-ba9b-48d3aaf1b9dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:08:13.445915Z",
     "iopub.status.busy": "2024-08-11T12:08:13.444672Z",
     "iopub.status.idle": "2024-08-11T12:08:13.465118Z",
     "shell.execute_reply": "2024-08-11T12:08:13.464384Z",
     "shell.execute_reply.started": "2024-08-11T12:08:13.445864Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import argparse\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "\n",
    "check_header = [\"任务状态\", \"备注\", \"任务\", \"行动\", \"事件\"]\n",
    "\n",
    "# 将OneKE模型的结果直接添加到input中，并生成新的output（多了verify字段，verify来自匹配成功的result）\n",
    "def add_verify_data(input_data, result_data):\n",
    "    data = input_data\n",
    "    result_data = result_data  # 直接使用传入的result_data\n",
    "\n",
    "    # 遍历每个元素\n",
    "    for item in data:\n",
    "        headers = item['table']['header']\n",
    "        table_data = item['table']['data']\n",
    "        verify = {}\n",
    "\n",
    "        # 初始化verify字典的每一行\n",
    "        for row_key in table_data.keys():\n",
    "            verify[row_key] = []\n",
    "\n",
    "        # 对每个header进行处理\n",
    "        for index, header in enumerate(headers):\n",
    "            # 获取对应的result_values\n",
    "            result_values = result_data.get(header, [])\n",
    "\n",
    "            # 遍历table_data中的每一行\n",
    "            for row_key, row_values in table_data.items():\n",
    "                value = row_values[index]\n",
    "\n",
    "                if value == \"\":\n",
    "                    verify[row_key].append(None)\n",
    "                    continue\n",
    "\n",
    "                matched_results = []\n",
    "\n",
    "                # 如果包含分号，进行拆分\n",
    "                sub_values = value.split('；') if '；' in value else [value]\n",
    "\n",
    "                # 与result_values中的值比较\n",
    "                for sub_value in sub_values:\n",
    "                    for result_value in result_values:\n",
    "                        # 计算相似度\n",
    "                        similarity = fuzz.ratio(sub_value.strip(), result_value)\n",
    "                        if similarity > 80:\n",
    "                            matched_results.append(result_value)\n",
    "\n",
    "                if matched_results:\n",
    "                    # 将多个匹配的result_value用分号连接起来\n",
    "                    verify_value = '；'.join(matched_results)\n",
    "                    verify[row_key].append(verify_value)\n",
    "                else:\n",
    "                    verify[row_key].append(None)\n",
    "\n",
    "        item['verify'] = verify\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# 对text分句\n",
    "def split_text(text):\n",
    "    # 按逗号和句号分句\n",
    "    sentences = text.replace('，', ',').replace('。', '.').split(',')\n",
    "    sub_sentences = []\n",
    "    for sentence in sentences:\n",
    "        sub_sentences.extend(sentence.split('.'))\n",
    "    return [s.strip() for s in sub_sentences if s.strip()]\n",
    "\n",
    "\n",
    "# 滑动窗口\n",
    "def sliding_window_compare(value, sub_sentences):\n",
    "    first_char = value[0]\n",
    "    best_match = None\n",
    "    highest_similarity = 0\n",
    "\n",
    "    # 遍历每个子句\n",
    "    for sub_sentence in sub_sentences:\n",
    "        # 找到包含首字符的位置\n",
    "        start_positions = [i for i in range(len(sub_sentence)) if sub_sentence[i] == first_char]\n",
    "\n",
    "        for start in start_positions:\n",
    "            # 滑动窗口进行比较\n",
    "            for end in range(start + 1, len(sub_sentence) + 1):\n",
    "                window = sub_sentence[start:end]\n",
    "                similarity = fuzz.ratio(value, window)\n",
    "                if similarity > 80 and similarity > highest_similarity:\n",
    "                    highest_similarity = similarity\n",
    "                    best_match = window\n",
    "\n",
    "    return best_match\n",
    "\n",
    "\n",
    "# 更新verify字段：verify来自匹配成功的data\n",
    "def update_verify_based_on_text(data):\n",
    "    text = data[0]['text']\n",
    "\n",
    "    # 分句\n",
    "    sub_sentences = split_text(text)\n",
    "\n",
    "    # 遍历每个元素\n",
    "    for item in data:\n",
    "        table_data = item['table']['data']\n",
    "        headers = item['table']['header']  # 获取header\n",
    "        verify = item.get('verify', {})\n",
    "\n",
    "        # 遍历table_data中的每一行\n",
    "        for row_key, row_values in table_data.items():\n",
    "            for index, value in enumerate(row_values):\n",
    "                header = headers[index]  # 获取当前值对应的header\n",
    "\n",
    "                # 判断条件：字符串长度大于等于7，或header为“任务状态”或“备注”\n",
    "                if len(value) >= 7 or (header in check_header and len(value) > 0):\n",
    "                    if len(value) >= 1:\n",
    "                        best_match = sliding_window_compare(value, sub_sentences)\n",
    "\n",
    "                        if best_match is not None:\n",
    "                            # 确保verify字典中有对应的key\n",
    "                            if row_key not in verify:\n",
    "                                verify[row_key] = [None] * len(row_values)\n",
    "                            # 将匹配的值放到verify中相应的位置\n",
    "                            verify[row_key][index] = value\n",
    "\n",
    "        # 更新item的verify字段\n",
    "        item['verify'] = verify\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b411b79b-7886-410b-a33a-586dfbfa5c9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:08:22.245622Z",
     "iopub.status.busy": "2024-08-11T12:08:22.244814Z",
     "iopub.status.idle": "2024-08-11T12:08:22.263840Z",
     "shell.execute_reply": "2024-08-11T12:08:22.263075Z",
     "shell.execute_reply.started": "2024-08-11T12:08:22.245560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2': ['2014年第四季度', None, None, 'E-2D先进鹰眼预警机', '预警机', '四架', '诺格公司', '美国海军航空测试和评估1中队', '初始作战试验和评估', '开始进行初始作战试验和评估阶段', '与空基早期告警和控制系统一起实现初始作战能力'], '3': ['2012年第二季度', None, None, None, None, None, None, None, None, None, None]}\n"
     ]
    }
   ],
   "source": [
    "# output_data_new = update_verify_based_on_text(add_verify_data(indict, result))\n",
    "file_path = 'results/test-useless2-input.json'\n",
    "result_path = 'results/test-useless2.json'\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        input_data = json.load(f)\n",
    "with open(result_path, 'r', encoding='utf-8') as f:\n",
    "        result_data = json.load(f)\n",
    "\n",
    "output_data = add_verify_data(input_data, result_data)\n",
    "output_data_new = update_verify_based_on_text(output_data)\n",
    "print(output_data_new[0]['verify'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "769a93e2-b537-419b-b786-2187f7ee92f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T13:13:07.725866Z",
     "iopub.status.busy": "2024-07-29T13:13:07.724609Z",
     "iopub.status.idle": "2024-07-29T13:13:15.171898Z",
     "shell.execute_reply": "2024-07-29T13:13:15.170975Z",
     "shell.execute_reply.started": "2024-07-29T13:13:07.725807Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"时间\": [\"去年五月\"], \"人物\": [], \"国家\": [], \"装备名称\": [\"导弹艇\"], \"装备类型\": [], \"装备数量\": [], \"组织机构\": [\"台湾海军\"], \"地点\": [], \"任务\": []}\n"
     ]
    }
   ],
   "source": [
    "sintruct2 = json.dumps(\n",
    "    {\n",
    "        \"instruction\": \"你是一个命名实体识别专家。请从input中抽取符合schema描述的实体，如果实体类型不存在就返回空列表，并输出为可解析的json格式。\",\n",
    "        \"schema\": {\n",
    "            \"时间\": \"实体类型描述事件的发生时间，具体可能是年份或者是可以体现出事情发生时间的表达，例如'2020年'，'9月23日'，'2013年春季'，'今晨'\",\n",
    "            \"人物\": \"指任何具体的人名，例如'海军上将格林纳特'。\",\n",
    "            \"国家\": \"实体类型指某个具体国家的名字，例如'美国'，'中国'，'俄罗斯'，'以色列'，'韩国'，'前苏联'。\",\n",
    "            \"装备名称\": \"实体类型描述任何军事装备的具体名称，例如'攻击型核潜艇'。\",\n",
    "            \"装备类型\": \"实体类型描述任何军事装备的类型，例如'潜艇'。\",\n",
    "            \"装备数量\": \"实体类型描述军事装备的具体数量，例如'2个中队，每个中队6艘'。\",\n",
    "            \"组织机构\": \"组织机构实体是指集体性质的组织，比如公司、商铺、俱乐部、学校等。它们在社会和经济活动中扮演一定角色，并拥有一定的人格权，例如'美国海军'，'俄罗斯海军'。\",\n",
    "            \"地点\": \"地点实体指具有地理位置信息的实体，它可以代表一个国家、城市、区域、街道等具体的地方或者一个抽象的地理区域。例如'康涅狄格州格罗顿海军基地'。\",\n",
    "            \"任务\": \"实体类型描述特定的任务目标，表示某种行为的目的，例如'军队重心向亚洲转移'。\" \n",
    "        },\n",
    "        \"input\": \"一些消息人士透露，这两张地图中包含有关台湾海军舰艇布署的情况。如果发生战争，丢失这两张地图将使台湾海军在面对敌方时失去战斗力。此外，还有一台导弹艇上的笔记本电脑在去年五月丢失，军方检察官认真对此展开调查。\"\n",
    "    },\n",
    "    ensure_ascii=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "sintruct2 = '<reserved_106>' + sintruct2 + '<reserved_107>'\n",
    "\n",
    "input_ids = tokenizer.encode(sintruct2, return_tensors=\"pt\").to(device)\n",
    "input_length = input_ids.size(1)\n",
    "generation_output = model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_length=512, max_new_tokens=256, return_dict_in_generate=True))\n",
    "generation_output = generation_output.sequences[0]\n",
    "generation_output = generation_output[input_length:]\n",
    "output = tokenizer.decode(generation_output, skip_special_tokens=True)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97089ee7-db5e-4cb1-96d2-87502663ae97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-09T14:44:59.037602Z",
     "iopub.status.busy": "2024-08-09T14:44:59.036750Z",
     "iopub.status.idle": "2024-08-09T14:44:59.062953Z",
     "shell.execute_reply": "2024-08-09T14:44:59.061648Z",
     "shell.execute_reply.started": "2024-08-09T14:44:59.037547Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import argparse\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "\n",
    "# 将OneKE模型的结果’result‘添加到’input‘中，并生成新的’output‘（多了verify字段，verify来自匹配成功的result）\n",
    "def add_verify_data(input_file, result_file, output_file):\n",
    "    # 读取input.json文件\n",
    "    with open(input_file, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # 读取result.json文件\n",
    "    with open(result_file, 'r', encoding='utf-8') as file:\n",
    "        result_data = json.load(file)['result']\n",
    "\n",
    "    # 遍历每个元素\n",
    "    for item in data:\n",
    "        headers = item['table']['header']\n",
    "        table_data = item['table']['data']\n",
    "        verify = {}\n",
    "\n",
    "        # 初始化verify字典的每一行\n",
    "        for row_key in table_data.keys():\n",
    "            verify[row_key] = []\n",
    "\n",
    "        # 对每个header进行处理\n",
    "        for index, header in enumerate(headers):\n",
    "            # 获取对应的result_values\n",
    "            result_values = result_data.get(header, [])\n",
    "\n",
    "            # 遍历table_data中的每一行\n",
    "            for row_key, row_values in table_data.items():\n",
    "                value = row_values[index]\n",
    "\n",
    "                if value == \"\":\n",
    "                    verify[row_key].append(None)\n",
    "                    continue\n",
    "\n",
    "                highest_similarity = 0\n",
    "                best_match = None\n",
    "\n",
    "                # 与result_values中的值比较\n",
    "                for result_value in result_values:\n",
    "                    # 计算相似度\n",
    "                    similarity = fuzz.ratio(value, result_value)\n",
    "                    if similarity > 90 and similarity > highest_similarity:\n",
    "                        highest_similarity = similarity\n",
    "                        best_match = result_value\n",
    "\n",
    "                if best_match is not None:\n",
    "                    verify[row_key].append(best_match)\n",
    "                else:\n",
    "                    verify[row_key].append(None)\n",
    "\n",
    "        item['verify'] = verify\n",
    "\n",
    "    # 将结果保存到output.json文件中\n",
    "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(data, outfile, indent=4, ensure_ascii=False)\n",
    "\n",
    "# 对text分句\n",
    "def split_text(text):\n",
    "    # 按逗号和句号分句\n",
    "    sentences = text.replace('，', ',').replace('。', '.').split(',')\n",
    "    sub_sentences = []\n",
    "    for sentence in sentences:\n",
    "        sub_sentences.extend(sentence.split('.'))\n",
    "    return [s.strip() for s in sub_sentences if s.strip()]\n",
    "\n",
    "# 滑动窗口\n",
    "def sliding_window_compare(value, sub_sentences):\n",
    "    first_char = value[0]\n",
    "    best_match = None\n",
    "    highest_similarity = 0\n",
    "\n",
    "    # 遍历每个子句\n",
    "    for sub_sentence in sub_sentences:\n",
    "        # 找到包含首字符的位置\n",
    "        start_positions = [i for i in range(len(sub_sentence)) if sub_sentence[i] == first_char]\n",
    "\n",
    "        for start in start_positions:\n",
    "            # 滑动窗口进行比较\n",
    "            for end in range(start + 1, len(sub_sentence) + 1):\n",
    "                window = sub_sentence[start:end]\n",
    "                similarity = fuzz.ratio(value, window)\n",
    "                if similarity > 80 and similarity > highest_similarity:\n",
    "                    highest_similarity = similarity\n",
    "                    best_match = window\n",
    "\n",
    "    return best_match\n",
    "\n",
    "# 更新verify字段：verify来自匹配成功的data\n",
    "def update_verify_based_on_text(output_file):\n",
    "    # 读取output.json文件\n",
    "    with open(output_file, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "        text = data[0]['text']\n",
    "\n",
    "    # 分句\n",
    "    sub_sentences = split_text(text)\n",
    "\n",
    "    # 遍历每个元素\n",
    "    for item in data:\n",
    "        table_data = item['table']['data']\n",
    "        verify = item.get('verify', {})\n",
    "\n",
    "        # 遍历table_data中的每一行\n",
    "        for row_key, row_values in table_data.items():\n",
    "            for index, value in enumerate(row_values):\n",
    "                if len(value) >= 7:\n",
    "                    best_match = sliding_window_compare(value, sub_sentences)\n",
    "\n",
    "                    if best_match is not None:\n",
    "                        # 确保verify字典中有对应的key\n",
    "                        if row_key not in verify:\n",
    "                            verify[row_key] = [None] * len(row_values)\n",
    "                        # 将匹配的值放到verify中相应的位置\n",
    "                        verify[row_key][index] = value\n",
    "\n",
    "        # 更新item的verify字段\n",
    "        item['verify'] = verify\n",
    "\n",
    "    # 将更新后的数据保存回output.json文件\n",
    "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(data, outfile, indent=4, ensure_ascii=False)\n",
    "\n",
    "def main():\n",
    "    # 读取参数\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--input_path\",\n",
    "        default='test-useless2-inp.json',\n",
    "        type=str,\n",
    "        # required=True,\n",
    "        help=\"Path to model input json.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--result_path\",\n",
    "        default= 'test-useless2.json',\n",
    "        type=str,\n",
    "        help=\"Path to OneKE result json.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output_path\",\n",
    "        default= 'results/output.json',  #totto_Train_data.jsonl\n",
    "        type=str,\n",
    "        help=\"Path to model output json.\"\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    # 将OneKE模型的结果’result‘添加到’input‘中，并生成新的’output‘（多了verify字段，verify来自匹配成功的result）\n",
    "    add_verify_data(args.input_path, args.result_path, args.output_path)\n",
    "\n",
    "    # 根据’output‘中的table字段和text字段（将table单元格内容与text做相似度匹配），更新’output‘中的verify字段（verify来自匹配成功的data）\n",
    "    update_verify_based_on_text(args.output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b63c820-62d4-4fb1-b541-73e26fb31d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
